{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldzqcVvvo7UF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ft6pDHgK5HJD"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 178742,
     "status": "ok",
     "timestamp": 1700234926467,
     "user": {
      "displayName": "Vinayak Sharma",
      "userId": "16409558266715913869"
     },
     "user_tz": -330
    },
    "id": "0xk5UnRzi2Dt",
    "outputId": "85d463de-fb92-4052-cc2b-5413a1d05c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Collecting torch==2.1.1\n",
      "  Downloading torch-2.1.1-cp39-cp39-win_amd64.whl (192.2 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (3.3.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (2.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (1.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (2.11.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ANKUR SINGH\\\\anaconda3\\\\Lib\\\\site-packages\\\\~orch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (2021.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.1->torchvision) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7909,
     "status": "ok",
     "timestamp": 1700291649859,
     "user": {
      "displayName": "Vinayak Sharma",
      "userId": "16409558266715913869"
     },
     "user_tz": -330
    },
    "id": "QUwhQO7W7JEe",
    "outputId": "f65c8b00-8f51-4b7a-bcb0-e2b5007de58e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ankur singh\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AkKn31_E7Z2L"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 4234,
     "status": "error",
     "timestamp": 1699890881896,
     "user": {
      "displayName": "Vinayak Sharma",
      "userId": "16409558266715913869"
     },
     "user_tz": -330
    },
    "id": "jnKC_Q4UvfjF",
    "outputId": "4a214c13-2ad1-4b86-dd29-e3e43da862fc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ANKURS~1\\AppData\\Local\\Temp/ipykernel_6440/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z07lbzgA8b-u"
   },
   "outputs": [],
   "source": [
    "#class for creating data loaders\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_names, labels, sequence_length=60, transform=None):\n",
    "        self.video_names = video_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        a = int(100 / self.count)\n",
    "        first_frame = np.random.randint(0, a)\n",
    "        temp_video = os.path.basename(video_path)\n",
    "        label = self.labels.loc[self.labels[\"FileName\"] == temp_video, \"label\"].item()\n",
    "        label = 0 if label == 'FAKE' else 1\n",
    "\n",
    "        for i, frame in enumerate(self.frame_extract(video_path)):\n",
    "            frames.append(self.transform(frame))\n",
    "            if len(frames) == self.count:\n",
    "                break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "\n",
    "        return frames, label\n",
    "\n",
    "    def frame_extract(self, path):\n",
    "        vidObj = cv2.VideoCapture(path)\n",
    "        success = 1\n",
    "        while success:\n",
    "            success, image = vidObj.read()\n",
    "            if success:\n",
    "                yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78EcYdY--8fN"
   },
   "outputs": [],
   "source": [
    "#Define data processing transformation\n",
    "\n",
    "def get_data_transforms(im_size=112):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((im_size, im_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    return train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dj1Eu37T9LlR"
   },
   "outputs": [],
   "source": [
    "#define model class\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "class MyModel(nn.Module):\n",
    "      def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(MyModel, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained = True) #Residual Network CNN\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048,num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "      def forward(self, x):\n",
    "          batch_size,seq_length, c, h, w = x.shape\n",
    "          x = x.view(batch_size * seq_length, c, h, w)\n",
    "          fmap = self.model(x)\n",
    "          x = self.avgpool(fmap)\n",
    "          x = x.view(batch_size,seq_length,2048)\n",
    "          x_lstm,_ = self.lstm(x,None)\n",
    "          return fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68qQemB_H1B6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "#method to train model\n",
    "\n",
    "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    t = []\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            targets = targets.type(torch.cuda.LongTensor)\n",
    "            inputs = inputs.cuda()\n",
    "        _, outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.type(torch.cuda.LongTensor))\n",
    "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        accuracies.update(acc, inputs.size(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                num_epochs,\n",
    "                i,\n",
    "                len(data_loader),\n",
    "                losses.avg,\n",
    "                accuracies.avg))\n",
    "    torch.save(model.state_dict(), '/content/checkpoint.pt')\n",
    "    return losses.avg, accuracies.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0VaasazM2za"
   },
   "outputs": [],
   "source": [
    "#method for testing model\n",
    "def test_epoch(epoch, model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    pred = []\n",
    "    true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
    "                inputs = inputs.cuda()\n",
    "            _, outputs = model(inputs)\n",
    "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
    "            acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
    "            _, p = torch.max(outputs, 1)\n",
    "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
    "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            accuracies.update(acc, inputs.size(0))\n",
    "            sys.stdout.write(\n",
    "                \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
    "                % (\n",
    "                    i,\n",
    "                    len(data_loader),\n",
    "                    losses.avg,\n",
    "                    accuracies.avg\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
    "    return true, pred, losses.avg, accuracies.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTPFHmoX-wof"
   },
   "outputs": [],
   "source": [
    "#importing training data and label file\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    header_list = [\"FileName\", \"label\",\"Dataset\"]\n",
    "    labels = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deepfake Detection Project/files/modifed_Files.csv', names=header_list)\n",
    "\n",
    "    video_files = glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/Celeb-DF_fake/*.mp4')\n",
    "    video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/Celeb-DF_real/*.mp4')\n",
    "    video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/DFD_fake/*.mp4')\n",
    "    video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/DFD_real/*.mp4')\n",
    "    video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/FF_fake/*.mp4')\n",
    "    video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/realface_only_data/FF_real/*.mp4')\n",
    "\n",
    "    random.shuffle(video_files)\n",
    "    random.shuffle(video_files)\n",
    "\n",
    "    frame_count = []\n",
    "    valid_video_files = []\n",
    "\n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        if int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) >= 100:\n",
    "            frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "            valid_video_files.append(video_file)\n",
    "\n",
    "    return labels, valid_video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY2oGZeWVYdB"
   },
   "outputs": [],
   "source": [
    "#calculate average\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QLkm0gIVr0L"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "#methods for accuracy, confusion matrix etc.\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    _, pred = outputs.topk(1, 1, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1))\n",
    "    n_correct_elems = correct.float().sum().item()\n",
    "    return 100* n_correct_elems / batch_size\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('True positive = ', cm[0][0])\n",
    "    print('False positive = ', cm[0][1])\n",
    "    print('False negative = ', cm[1][0])\n",
    "    print('True negative = ', cm[1][1])\n",
    "    print('\\n')\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "    plt.ylabel('Actual label', size = 20)\n",
    "    plt.xlabel('Predicted label', size = 20)\n",
    "    plt.xticks(np.arange(2), ['FAKE', 'REAL'], size = 16)\n",
    "    plt.yticks(np.arange(2), ['FAKE', 'REAL'], size = 16)\n",
    "    plt.ylim([2, 0])\n",
    "    plt.show()\n",
    "    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n",
    "    print(\"Calculated Accuracy\",calculated_acc*100)\n",
    "\n",
    "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
    "  loss_train = train_loss_avg\n",
    "  loss_val = test_loss_avg\n",
    "  print(num_epochs)\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "  plt.title('Training and Validation loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
    "  loss_train = train_accuracy\n",
    "  loss_val = test_accuracy\n",
    "  epochs = range(1,num_epochs+1)\n",
    "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "  plt.title('Training and Validation accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1745042,
     "status": "ok",
     "timestamp": 1701510600799,
     "user": {
      "displayName": "Vinayak Sharma",
      "userId": "16409558266715913869"
     },
     "user_tz": -330
    },
    "id": "Knwu3mp8_hug",
    "outputId": "2956683b-cd4c-4cb3-b4ee-849090e09746"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set device and other configurations\n",
    "\n",
    "    # Data preprocessing transforms\n",
    "    data_transforms = get_data_transforms()\n",
    "\n",
    "    # Load labels and video files\n",
    "    labels, video_files = load_data()\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    train_ratio = 0.8\n",
    "    split_index = int(train_ratio * len(video_files))\n",
    "    train_videos = video_files[:split_index]\n",
    "    valid_videos = video_files[split_index:]\n",
    "\n",
    "    # Create data loaders\n",
    "    train_data = VideoDataset(train_videos, labels, sequence_length=10, transform=data_transforms)\n",
    "    train_loader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "    valid_data = VideoDataset(valid_videos, labels, sequence_length=10, transform=data_transforms)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Define the model\n",
    "    model = MyModel(2).cuda()\n",
    "\n",
    "    # Set hyperparameters\n",
    "\n",
    "    # Learning rate\n",
    "    lr = 1e-5  # 0.001\n",
    "    # Number of epochs\n",
    "    num_epochs = 8\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    # Train the model and test\n",
    "    train_loss_avg = []\n",
    "    train_accuracy = []\n",
    "    test_loss_avg = []\n",
    "    test_accuracy = []\n",
    "    train_accuracy_per_step = []  # Store training accuracy at each step\n",
    "    test_accuracy_per_step = []  # Store validation accuracy at each step\n",
    "\n",
    "    # Initialize tqdm\n",
    "    t = tqdm(total=num_epochs, desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(epoch, num_epochs, train_loader, model, criterion, optimizer)\n",
    "        train_loss_avg.append(train_loss)\n",
    "        train_accuracy.append(train_acc)\n",
    "        train_accuracy_per_step.append(train_acc)  # Store accuracy at each step\n",
    "\n",
    "        true, pred, test_loss, test_acc = test_epoch(epoch, model, valid_loader, criterion)\n",
    "        test_loss_avg.append(test_loss)\n",
    "        test_accuracy.append(test_acc)\n",
    "        test_accuracy_per_step.append(test_acc)  # Store accuracy at each step\n",
    "\n",
    "        t.set_postfix(train_loss=train_loss, train_acc=train_acc, test_loss=test_loss, test_acc=test_acc)\n",
    "        t.update()\n",
    "\n",
    "    t.close()\n",
    "\n",
    "    # Plot loss and accuracy, and output confusion matrix\n",
    "    plot_loss(train_loss_avg, test_loss_avg, num_epochs)\n",
    "    plot_accuracy(train_accuracy, test_accuracy, num_epochs)\n",
    "\n",
    "    # Plot continuous accuracy versus epochs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracy_per_step, label='Training Accuracy')\n",
    "    plt.plot(range(1, num_epochs + 1), test_accuracy_per_step, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Continuous Accuracy vs. Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(confusion_matrix(true, pred))\n",
    "    print_confusion_matrix(true, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcUnL5Iu84kH"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model(1).pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTF7qSnrEJu4MVKyd/HdDr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
